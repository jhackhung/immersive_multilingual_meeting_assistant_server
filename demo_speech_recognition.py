#!/usr/bin/env python3
"""
èªéŸ³è­˜åˆ¥æœå‹™æ¼”ç¤ºè…³æœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°å¢çš„èªéŸ³è­˜åˆ¥åŠŸèƒ½
"""

import os
import tempfile
import logging
from apis.speech_recognition_service import SpeechRecognitionServicer

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_test_audio():
    """å‰µå»ºä¸€å€‹ç°¡å–®çš„æ¸¬è©¦éŸ³è¨Šæ–‡ä»¶ï¼ˆä½¿ç”¨ TTSï¼‰"""
    try:
        from TTS.api import TTS
        import torch
        
        # åˆå§‹åŒ– TTS
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        tts = TTS("tts_models/en/ljspeech/tacotron2-DDC").to(device)
        
        # ç”Ÿæˆæ¸¬è©¦éŸ³è¨Š
        test_text = "Hello, this is a test of the speech recognition service. The weather is nice today."
        
        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        temp_file.close()
        
        # ç”ŸæˆéŸ³è¨Š
        tts.tts_to_file(text=test_text, file_path=temp_file.name)
        
        logger.info(f"æ¸¬è©¦éŸ³è¨Šå·²ç”Ÿæˆ: {temp_file.name}")
        logger.info(f"åŸå§‹æ–‡æœ¬: {test_text}")
        
        return temp_file.name, test_text
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ¸¬è©¦éŸ³è¨Šå¤±æ•—: {e}")
        return None, None

def test_standalone_speech_recognition():
    """æ¸¬è©¦ç¨ç«‹çš„èªéŸ³è­˜åˆ¥æœå‹™"""
    
    logger.info("=== èªéŸ³è­˜åˆ¥æœå‹™ç¨ç«‹æ¸¬è©¦ ===")
    
    # åˆå§‹åŒ–èªéŸ³è­˜åˆ¥æœå‹™
    logger.info("æ­£åœ¨åˆå§‹åŒ–èªéŸ³è­˜åˆ¥æœå‹™...")
    speech_recognizer = SpeechRecognitionServicer(model_size="base")
    
    if not speech_recognizer.initialize():
        logger.error("âŒ èªéŸ³è­˜åˆ¥æœå‹™åˆå§‹åŒ–å¤±æ•—")
        return
    
    logger.info("âœ… èªéŸ³è­˜åˆ¥æœå‹™åˆå§‹åŒ–æˆåŠŸ")
    
    # æª¢æŸ¥æ”¯æ´çš„èªè¨€
    supported_languages = speech_recognizer.get_supported_languages()
    logger.info(f"æ”¯æ´çš„èªè¨€: {list(supported_languages.keys())}")
    
    # æª¢æŸ¥æ¨¡å‹è³‡è¨Š
    model_info = speech_recognizer.get_model_info()
    logger.info(f"æ¨¡å‹è³‡è¨Š: {model_info}")
    
    # æ¸¬è©¦ç¾æœ‰éŸ³è¨Šæ–‡ä»¶
    test_files = [
        "./tts_sample/en_sample.wav",
        "./tts_sample/segment.wav",
        "./identify_sample/ta.wav"
    ]
    
    for audio_file in test_files:
        if os.path.exists(audio_file):
            logger.info(f"\n--- æ¸¬è©¦éŸ³è¨Šæ–‡ä»¶: {audio_file} ---")
            
            try:
                # è®€å–éŸ³è¨Šæ–‡ä»¶
                with open(audio_file, 'rb') as f:
                    audio_data = f.read()
                
                # æ¸¬è©¦åŸºæœ¬è½‰éŒ„
                logger.info("åŸ·è¡ŒåŸºæœ¬èªéŸ³è½‰éŒ„...")
                result = speech_recognizer.transcribe_audio(
                    audio_data=audio_data,
                    language="auto",
                    return_timestamps=False
                )
                
                if result["success"]:
                    logger.info(f"âœ… è½‰éŒ„æˆåŠŸ")
                    logger.info(f"   è½‰éŒ„æ–‡æœ¬: {result['transcribed_text']}")
                    logger.info(f"   æª¢æ¸¬èªè¨€: {result['detected_language']}")
                else:
                    logger.error(f"âŒ è½‰éŒ„å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                
                # æ¸¬è©¦å¸¶æ™‚é–“æˆ³çš„è½‰éŒ„
                logger.info("åŸ·è¡Œå¸¶æ™‚é–“æˆ³çš„èªéŸ³è½‰éŒ„...")
                result_with_timestamps = speech_recognizer.transcribe_audio(
                    audio_data=audio_data,
                    language="auto",
                    return_timestamps=True
                )
                
                if result_with_timestamps["success"] and result_with_timestamps["segments"]:
                    logger.info(f"âœ… å¸¶æ™‚é–“æˆ³è½‰éŒ„æˆåŠŸ")
                    logger.info(f"   å…± {len(result_with_timestamps['segments'])} å€‹ç‰‡æ®µ:")
                    for i, segment in enumerate(result_with_timestamps["segments"]):
                        logger.info(f"     ç‰‡æ®µ {i+1}: [{segment['start_time']:.2f}s - {segment['end_time']:.2f}s] {segment['text']}")
                
            except Exception as e:
                logger.error(f"âŒ è™•ç†éŸ³è¨Šæ–‡ä»¶ {audio_file} æ™‚å‡ºéŒ¯: {e}")
        else:
            logger.warning(f"âš ï¸ éŸ³è¨Šæ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
    
    # å¦‚æœæ²’æœ‰ç¾æœ‰éŸ³è¨Šæ–‡ä»¶ï¼Œå˜—è©¦ç”Ÿæˆæ¸¬è©¦éŸ³è¨Š
    if not any(os.path.exists(f) for f in test_files):
        logger.info("\n--- ç”Ÿæˆæ¸¬è©¦éŸ³è¨Šé€²è¡Œæ¼”ç¤º ---")
        test_audio_path, original_text = create_test_audio()
        
        if test_audio_path:
            try:
                with open(test_audio_path, 'rb') as f:
                    audio_data = f.read()
                
                logger.info("ä½¿ç”¨ç”Ÿæˆçš„æ¸¬è©¦éŸ³è¨Šé€²è¡Œè½‰éŒ„...")
                result = speech_recognizer.transcribe_audio(
                    audio_data=audio_data,
                    language="en",
                    return_timestamps=True
                )
                
                if result["success"]:
                    logger.info(f"âœ… è½‰éŒ„æˆåŠŸ")
                    logger.info(f"   åŸå§‹æ–‡æœ¬: {original_text}")
                    logger.info(f"   è½‰éŒ„æ–‡æœ¬: {result['transcribed_text']}")
                    logger.info(f"   æª¢æ¸¬èªè¨€: {result['detected_language']}")
                    
                    if result["segments"]:
                        logger.info(f"   æ™‚é–“æˆ³ç‰‡æ®µ:")
                        for i, segment in enumerate(result["segments"]):
                            logger.info(f"     ç‰‡æ®µ {i+1}: [{segment['start_time']:.2f}s - {segment['end_time']:.2f}s] {segment['text']}")
                
                # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                os.unlink(test_audio_path)
                
            except Exception as e:
                logger.error(f"âŒ æ¸¬è©¦ç”Ÿæˆçš„éŸ³è¨Šæ™‚å‡ºéŒ¯: {e}")

def demonstrate_features():
    """æ¼”ç¤ºèªéŸ³è­˜åˆ¥æœå‹™çš„å„ç¨®ç‰¹æ€§"""
    
    logger.info("=== èªéŸ³è­˜åˆ¥æœå‹™ç‰¹æ€§æ¼”ç¤º ===")
    
    # é¡¯ç¤ºæœå‹™è³‡è¨Š
    speech_recognizer = SpeechRecognitionServicer()
    
    logger.info("\nğŸ¤ èªéŸ³è­˜åˆ¥æœå‹™ç‰¹æ€§:")
    logger.info("   â€¢ æ”¯æ´å¤šç¨®èªè¨€çš„èªéŸ³è½‰æ–‡å­—")
    logger.info("   â€¢ è‡ªå‹•èªè¨€æª¢æ¸¬")
    logger.info("   â€¢ æ™‚é–“æˆ³ä¿¡æ¯æå–")
    logger.info("   â€¢ å¤šç¨®æ¨¡å‹å¤§å°é¸æ“‡ (tiny, base, small, medium, large)")
    logger.info("   â€¢ é«˜æº–ç¢ºåº¦çš„ OpenAI Whisper æ¨¡å‹")
    
    supported_languages = speech_recognizer.get_supported_languages()
    logger.info(f"\nğŸŒ æ”¯æ´çš„èªè¨€ ({len(supported_languages)} ç¨®):")
    for code, name in supported_languages.items():
        logger.info(f"   â€¢ {code}: {name}")
    
    logger.info("\nğŸ“‹ ä½¿ç”¨å ´æ™¯:")
    logger.info("   â€¢ æœƒè­°è¨˜éŒ„è½‰éŒ„")
    logger.info("   â€¢ å¤šèªè¨€éŸ³è¨Šå…§å®¹åˆ†æ")
    logger.info("   â€¢ èªéŸ³åŠ©æ‰‹äº¤äº’")
    logger.info("   â€¢ éŸ³è¨Šå…§å®¹æœç´¢èˆ‡ç´¢å¼•")
    logger.info("   â€¢ èªè¨€å­¸ç¿’è¼”åŠ©")
    
    logger.info("\nğŸ”§ API ä½¿ç”¨æ–¹å¼:")
    logger.info("   â€¢ gRPC ç«¯é»: MediaService.SpeechRecognition")
    logger.info("   â€¢ è¼¸å…¥: éŸ³è¨Š bytes + èªè¨€è¨­å®š + é¸é …")
    logger.info("   â€¢ è¼¸å‡º: è½‰éŒ„æ–‡æœ¬ + èªè¨€æª¢æ¸¬ + æ™‚é–“æˆ³(å¯é¸)")

if __name__ == "__main__":
    logger.info("ğŸ¤ èªéŸ³è­˜åˆ¥æœå‹™æ¼”ç¤ºé–‹å§‹")
    
    # æ¼”ç¤ºæœå‹™ç‰¹æ€§
    demonstrate_features()
    
    print("\n" + "="*60)
    
    # åŸ·è¡Œå¯¦éš›æ¸¬è©¦
    test_standalone_speech_recognition()
    
    logger.info("\nğŸ¤ èªéŸ³è­˜åˆ¥æœå‹™æ¼”ç¤ºå®Œæˆ")
    logger.info("\nğŸ’¡ æç¤º: å¯ä»¥é€šé gRPC å®¢æˆ¶ç«¯èª¿ç”¨ MediaService.SpeechRecognition ä½¿ç”¨æ­¤æœå‹™")
