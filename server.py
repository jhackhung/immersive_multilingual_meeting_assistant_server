print("!!! SERVER.PY HAS BEEN MODIFIED SUCCESSFULLY !!!")

from concurrent import futures
import grpc
import time
import logging

# åŒ¯å…¥ gRPC æ¨¡çµ„
from proto import model_service_pb2
from proto import model_service_pb2_grpc

# åŒ¯å…¥æ‰€æœ‰ API æœå‹™å±¤
from apis.wav2lip_service import Wav2LipServicer
from apis.translator_service import TranslatorService
from apis.tts_service import TtsServicer
from apis.llm_service import LLMServicer
from apis.speech_recognition_service import SpeechRecognitionServicer

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- å®šç¾©ä¸€å€‹è¼ƒå¤§çš„è¨Šæ¯é•·åº¦ï¼Œä¾‹å¦‚ 100MB ---
MAX_MESSAGE_LENGTH = 100 * 1024 * 1024
# --- å¢åŠ å…ƒæ•¸æ“šå¤§å°é™åˆ¶ ---
MAX_METADATA_SIZE = 2 * 1024 * 1024  # 2MB

class TranslatorServicer(model_service_pb2_grpc.TranslatorServiceServicer):
    """gRPC ç¿»è­¯æœå‹™å¯¦ç¾"""
    
    def __init__(self, translator_api: TranslatorService):
        self.translator_api = translator_api
        logger.info("TranslatorServicer å·²åˆå§‹åŒ–")

    def Translate(self, request, context):
        request_data = {
            "text": request.text_to_translate,
            "source_lang": request.source_language,
            "target_lang": request.target_language
        }
        logger.info(f"æ”¶åˆ°ç¿»è­¯è«‹æ±‚: {request_data}")
        result = self.translator_api.process_translation_request(request_data)
        if result["success"]:
            return model_service_pb2.TranslateResponse(
                translated_text=result["translated_text"]
            )
        else:
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(result["error"])
            return model_service_pb2.TranslateResponse()

class MediaServicer(model_service_pb2_grpc.MediaServiceServicer):
    """çµ±ä¸€çš„åª’é«”æœå‹™å¯¦ç¾"""
    
    def __init__(self, tts_servicer, wav2lip_servicer, speaker_annote_servicer, llm_servicer, speech_recognition_servicer):
        self.tts_servicer = tts_servicer
        self.wav2lip_servicer = wav2lip_servicer
        self.speaker_annote_servicer = speaker_annote_servicer
        self.llm_servicer = llm_servicer
        self.speech_recognition_servicer = speech_recognition_servicer
        logger.info("MediaServicer å·²åˆå§‹åŒ–ï¼ˆåŒ…å« LLM å’ŒèªéŸ³è­˜åˆ¥æœå‹™ï¼‰")
    
    def Tts(self, request, context):
        logger.info("æ”¶åˆ° TTS è«‹æ±‚")
        return self.tts_servicer.Tts(request, context)
    
    def Wav2Lip(self, request, context):
        logger.info("æ”¶åˆ° Wav2Lip è«‹æ±‚")
        return self.wav2lip_servicer.Wav2Lip(request, context)
    
    def SpeakerAnnote(self, request, context):
        logger.info("æ”¶åˆ° SpeakerAnnote è«‹æ±‚")
        return self.speaker_annote_servicer.SpeakerAnnote(request, context)
    
    def SpeechRecognition(self, request, context):
        logger.info("æ”¶åˆ° SpeechRecognition è«‹æ±‚")
        if self.speech_recognition_servicer:
            return self.speech_recognition_servicer.SpeechRecognition(request, context)
        else:
            context.set_code(grpc.StatusCode.UNIMPLEMENTED)
            context.set_details("èªéŸ³è­˜åˆ¥æœå‹™æœªå•Ÿç”¨")
            return model_service_pb2.SpeechRecognitionResponse(
                success=False
            )
    
    def GenerateText(self, request, context):
        logger.info("æ”¶åˆ° GenerateText è«‹æ±‚")
        if self.llm_servicer:
            return self.llm_servicer.GenerateText(request, context)
        else:
            context.set_code(grpc.StatusCode.UNIMPLEMENTED)
            context.set_details("LLM æœå‹™æœªå•Ÿç”¨")
            return model_service_pb2.TextGenerationResponse(
                generated_text="",
                success=False
            )
    
    def ChatCompletion(self, request, context):
        logger.info("æ”¶åˆ° ChatCompletion è«‹æ±‚")
        if self.llm_servicer:
            return self.llm_servicer.ChatCompletion(request, context)
        else:
            context.set_code(grpc.StatusCode.UNIMPLEMENTED)
            context.set_details("LLM æœå‹™æœªå•Ÿç”¨")
            return model_service_pb2.ChatCompletionResponse(
                response="",
                success=False
            )

class SpeakerAnnoteServicer:
    """èªè€…è¾¨è­˜æœå‹™çš„åŒ…è£å™¨"""
    
    def __init__(self):
        self.diarization_model = None
        logger.info("SpeakerAnnoteServicer å·²åˆå§‹åŒ–")
    
    def initialize(self) -> bool:
        try:
            from apis.identify import OfficialRealtimeDiarizer
            logger.info("æ­£åœ¨è¼‰å…¥èªè€…è¾¨è­˜æ¨¡å‹...")
            self.diarization_model = OfficialRealtimeDiarizer(clustering_threshold=0.7)
            logger.info("èªè€…è¾¨è­˜æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"èªè€…è¾¨è­˜æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
            return False
            
    def _merge_segments(self, diarization_results, max_silence_for_merge=2.0):
        """ä¸€å€‹ä¸ä¾è³´ç‰¹å®šå¥—ä»¶ç‰ˆæœ¬çš„æ‰‹å‹•åˆä½µå‡½å¼ã€‚"""
        if not diarization_results:
            return []

        # ç¢ºä¿ç‰‡æ®µæŒ‰é–‹å§‹æ™‚é–“æ’åº
        diarization_results.sort(key=lambda x: x[1])

        merged = []
        current_speaker, current_start, current_end = diarization_results[0]

        for i in range(1, len(diarization_results)):
            next_speaker, next_start, next_end = diarization_results[i]

            if (next_speaker == current_speaker and
                (next_start - current_end) < max_silence_for_merge):
                current_end = next_end
            else:
                merged.append((current_speaker, current_start, current_end))
                current_speaker, current_start, current_end = next_speaker, next_start, next_end

        merged.append((current_speaker, current_start, current_end))
        return merged

    def SpeakerAnnote(self, request, context):
        if self.diarization_model is None:
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details("èªè€…è¾¨è­˜æ¨¡å‹æœªåˆå§‹åŒ–")
            return model_service_pb2.SpeakerAnnoteResponse()
        
        try:
            logger.info(f"æ”¶åˆ°èªè€…è¾¨è­˜è«‹æ±‚ï¼ŒéŸ³è¨Šæ•¸æ“šå¤§å°: {len(request.audio_data)} bytes")
            
            import io
            import soundfile as sf
            import numpy as np
            
            audio_buffer = io.BytesIO(request.audio_data)
            audio_data, sample_rate = sf.read(audio_buffer)
            
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)
            audio_data = audio_data.astype(np.float32)
            
            if sample_rate != 16000:
                import librosa
                audio_data = librosa.resample(y=audio_data, orig_sr=sample_rate, target_sr=16000)
                logger.info("å·²å°‡éŸ³è¨Šé‡æ–°æ¡æ¨£è‡³ 16000Hz")
            
            self.diarization_model.process(audio_data)
            
            # *** THIS IS THE FIX: Directly use the list returned by flush() ***
            raw_segments = self.diarization_model.flush()
            
            logger.info(f"è¬›è€…åˆ†è¾¨å®Œæˆï¼ŒåŸå§‹ç‰‡æ®µæ•¸é‡: {len(raw_segments)}")

            # ä½¿ç”¨åŸå§‹åˆ—è¡¨ä¾†é€²è¡Œåˆä½µ
            merged_results = self._merge_segments(raw_segments)
            logger.info(f"ç‰‡æ®µåˆä½µå®Œæˆï¼Œåˆä½µå¾Œç‰‡æ®µæ•¸é‡: {len(merged_results)}")

            all_segments = []
            speaker_timelines = {}
            
            for speaker, start_time, end_time in merged_results:
                segment = model_service_pb2.DiarizationSegment(
                    speaker=speaker,
                    start_time=float(start_time),
                    end_time=float(end_time)
                )
                all_segments.append(segment)
                
                if speaker not in speaker_timelines:
                    speaker_timelines[speaker] = []
                speaker_timelines[speaker].append(segment)
            
            timeline_objects = []
            for speaker, segments in speaker_timelines.items():
                timeline = model_service_pb2.SpeakerTimeline(
                    speaker=speaker,
                    segments=segments
                )
                timeline_objects.append(timeline)
            
            response = model_service_pb2.SpeakerAnnoteResponse(
                all_segments=all_segments,
                speaker_timelines=timeline_objects
            )
            
            logger.info("è¬›è€…åˆ†è¾¨çµæœå·²æº–å‚™å®Œæˆ")
            return response
            
        except Exception as e:
            logger.error(f"èªè€…è¾¨è­˜è™•ç†å¤±æ•—: {e}")
            import traceback
            logger.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"èªè€…è¾¨è­˜è™•ç†å¤±æ•—: {str(e)}")
            return model_service_pb2.SpeakerAnnoteResponse()

class ServerManager:
    """ä¼ºæœå™¨ç®¡ç†å™¨ï¼Œè² è²¬åˆå§‹åŒ–å’Œç®¡ç†æ‰€æœ‰æœå‹™"""
    
    def __init__(self):
        self.translator_api = None
        self.tts_servicer = None
        self.wav2lip_servicer = None
        self.speaker_annote_servicer = None
        self.llm_servicer = None
        self.speech_recognition_servicer = None
        self.server = None
        
    def initialize_models(self) -> bool:
        try:
            logger.info("æ­£åœ¨åˆå§‹åŒ–ç¿»è­¯æœå‹™...")
            self.translator_api = TranslatorService()
            if not self.translator_api.initialize():
                return False
            
            logger.info("æ­£åœ¨åˆå§‹åŒ– TTS æœå‹™...")
            self.tts_servicer = TtsServicer()
            
            logger.info("æ­£åœ¨åˆå§‹åŒ– Wav2Lip æœå‹™...")
            self.wav2lip_servicer = Wav2LipServicer()
            
            logger.info("æ­£åœ¨åˆå§‹åŒ–èªè€…è¾¨è­˜æœå‹™...")
            self.speaker_annote_servicer = SpeakerAnnoteServicer()
            if not self.speaker_annote_servicer.initialize():
                logger.warning("èªè€…è¾¨è­˜æœå‹™åˆå§‹åŒ–å¤±æ•—ï¼Œä½†ç¹¼çºŒå•Ÿå‹•å…¶ä»–æœå‹™")
            
            logger.info("æ­£åœ¨åˆå§‹åŒ–èªéŸ³è­˜åˆ¥æœå‹™...")
            try:
                self.speech_recognition_servicer = SpeechRecognitionServicer(model_size="base")
                if self.speech_recognition_servicer.initialize():
                    logger.info("âœ… èªéŸ³è­˜åˆ¥æœå‹™åˆå§‹åŒ–æˆåŠŸ")
                else:
                    logger.warning("âŒ èªéŸ³è­˜åˆ¥æœå‹™åˆå§‹åŒ–å¤±æ•—ï¼Œä½†ç¹¼çºŒå•Ÿå‹•å…¶ä»–æœå‹™")
                    self.speech_recognition_servicer = None
            except Exception as e:
                logger.warning(f"âŒ èªéŸ³è­˜åˆ¥æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}ï¼Œä½†ç¹¼çºŒå•Ÿå‹•å…¶ä»–æœå‹™")
                self.speech_recognition_servicer = None
            
            logger.info("æ­£åœ¨åˆå§‹åŒ– LLM æœå‹™...")
            try:
                # ä½¿ç”¨è¼•é‡ç´šæ¨¡å‹ä»¥æ¸›å°‘å…§å­˜ä½¿ç”¨
                self.llm_servicer = LLMServicer(model_name="gpt2")  # ä½¿ç”¨å®Œæ•´ç‰ˆä½†é¸æ“‡è¼ƒå°çš„æ¨¡å‹
                logger.info("âœ… LLM æœå‹™åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âŒ LLM æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}ï¼Œä½†ç¹¼çºŒå•Ÿå‹•å…¶ä»–æœå‹™")
                logger.warning("å¦‚æœé‡åˆ° numpy å…¼å®¹æ€§å•é¡Œï¼Œè«‹é‹è¡Œ:")
                logger.warning("pip uninstall numpy pandas scikit-learn transformers torch -y")
                logger.warning("pip install numpy==1.24.3 pandas==2.0.3 scikit-learn==1.3.0")
                logger.warning("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu")
                logger.warning("pip install transformers==4.30.0")
                self.llm_servicer = None
            
            return True
            
        except Exception as e:
            logger.error(f"æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
            return False
    
    def setup_server(self):
        self.server = grpc.server(
            futures.ThreadPoolExecutor(max_workers=10),
            options=[
                ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),
                ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),
                ('grpc.max_receive_metadata_size', MAX_METADATA_SIZE),
                ('grpc.max_send_metadata_size', MAX_METADATA_SIZE),
            ]
        )
        
        model_service_pb2_grpc.add_TranslatorServiceServicer_to_server(
            TranslatorServicer(self.translator_api), 
            self.server
        )
        
        # ä¿®æ”¹ MediaServicer åˆå§‹åŒ–ï¼ŒåŠ å…¥ LLM å’ŒèªéŸ³è­˜åˆ¥æœå‹™
        media_servicer = MediaServicer(
            tts_servicer=self.tts_servicer,
            wav2lip_servicer=self.wav2lip_servicer,
            speaker_annote_servicer=self.speaker_annote_servicer,
            llm_servicer=self.llm_servicer,
            speech_recognition_servicer=self.speech_recognition_servicer
        )
        model_service_pb2_grpc.add_MediaServiceServicer_to_server(
            media_servicer, 
            self.server
        )
        
        self.server.add_insecure_port('0.0.0.0:50051')
        logger.info("gRPC ä¼ºæœå™¨è¨­å®šå®Œæˆï¼ˆåŒ…å« LLM å’ŒèªéŸ³è­˜åˆ¥æœå‹™ï¼‰")
    
    def start_server(self):
        if not self.initialize_models():
            logger.error("æœå‹™åˆå§‹åŒ–å¤±æ•—ï¼Œä¼ºæœå™¨ç„¡æ³•å•Ÿå‹•")
            return
        
        self.setup_server()
        self.server.start()
        
        # é¡¯ç¤ºå¯ç”¨æœå‹™
        services = ["ğŸ”¤ ç¿»è­¯æœå‹™", "ğŸ”Š TTS æœå‹™", "ğŸ¬ Wav2Lip æœå‹™"]
        if self.speaker_annote_servicer:
            services.append("ğŸ‘¥ èªè€…è¾¨è­˜æœå‹™")
        if self.speech_recognition_servicer:
            services.append("ğŸ¤ èªéŸ³è­˜åˆ¥æœå‹™")
        if self.llm_servicer:
            services.append("ğŸ¤– LLM æœå‹™")
        
        logger.info("ğŸš€ gRPC ä¼ºæœå™¨å·²æˆåŠŸå•Ÿå‹•ï¼Œç›£è½åŸ  50051...")
        logger.info(f"ğŸ“‹ å¯ç”¨æœå‹™: {', '.join(services)}")
        
        try:
            while True:
                time.sleep(86400)
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°é—œé–‰ä¿¡è™Ÿï¼Œæ­£åœ¨é—œé–‰ä¼ºæœå™¨...")
            self.server.stop(0)
            logger.info("ä¼ºæœå™¨å·²é—œé–‰")
        
def serve():
    server_manager = ServerManager()
    server_manager.start_server()

if __name__ == '__main__':
    serve()