import grpc
import numpy as np
import wave
from proto import model_service_pb2
from proto import model_service_pb2_grpc

# --- æ–°å¢ï¼šå®šç¾©èˆ‡ä¼ºæœå™¨ç«¯åŒ¹é…çš„è¨Šæ¯é•·åº¦é™åˆ¶ ---
MAX_MESSAGE_LENGTH = 100 * 1024 * 1024
# --- å¢åŠ å…ƒæ•¸æ“šå¤§å°é™åˆ¶ ---
MAX_METADATA_SIZE = 2 * 1024 * 1024  # 2MB

def run_rag_qa_test(stub, query):
    """æ¸¬è©¦ RAG å•ç­”åŠŸèƒ½"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ RAG å•ç­”è«‹æ±‚: '{query}'")
    
    try:
        # æº–å‚™è«‹æ±‚ç‰©ä»¶
        request = model_service_pb2.AnswerQuestionRequest(query=query)
        
        # å‘¼å«é ç«¯çš„ AnswerQuestionFromDocuments æœå‹™
        response = stub.AnswerQuestionFromDocuments(request)
        
        # æª¢æŸ¥å›æ‡‰
        if response.success:
            print(f"âœ… [å®¢æˆ¶ç«¯] RAG å•ç­”æˆåŠŸ:")
            print(f"ğŸ¤– æ¨¡å‹å›ç­”: {response.answer}")
            if response.sources:
                print(f"ğŸ“š åƒè€ƒä¾†æº:")
                for source in response.sources:
                    print(f"  - {source}")
        else:
            print("âŒ [å®¢æˆ¶ç«¯] RAG å•ç­”å¤±æ•—")
            
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] RAG å•ç­”è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")
    except Exception as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è™•ç† RAG å•ç­”æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def run_tts_test(stub, text, language, output_filename):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨ä¾†åŸ·è¡Œå–®æ¬¡ TTS ä¸¦å„²å­˜çµæœ"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ TTS è«‹æ±‚: '{text}' (èªè¨€: {language})")
    try:
        # æº–å‚™è«‹æ±‚ç‰©ä»¶ï¼ŒåŒ…å«æ–‡å­—å’Œèªè¨€
        reference_audio_file_path = "./tts_sample/en_sample.wav"
        with open(reference_audio_file_path, "rb") as f:
            reference_audio = f.read()
        # æº–å‚™è«‹æ±‚ç‰©ä»¶ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦çš„æ¬„ä½
        
        request = model_service_pb2.TtsRequest(
            text_to_speak=text,
            language=language,
            reference_audio=reference_audio
        )
        
        # å‘¼å«é ç«¯çš„ Tts æœå‹™
        response = stub.Tts(request)
        
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦æœ‰éŸ³è¨Šè³‡æ–™
        if response.generated_audio:
            with open(output_filename, "wb") as f:
                f.write(response.generated_audio)
            print(f"âœ… [å®¢æˆ¶ç«¯] æ”¶åˆ°éŸ³è¨Šå›æ‡‰ï¼Œå·²ä¿å­˜è‡³ {output_filename}")
        else:
            print("âŒ [å®¢æˆ¶ç«¯] ä¼ºæœå™¨å›å‚³äº†ç©ºçš„éŸ³è¨Šã€‚")
            
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] TTS è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")

def run_translation_test(stub, text, src_lang, tgt_lang):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨ä¾†åŸ·è¡Œå–®æ¬¡ç¿»è­¯ä¸¦å°å‡ºçµæœ"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ç¿»è­¯è«‹æ±‚: '{text}' ({src_lang} -> {tgt_lang})")
    
    try:
        # æº–å‚™è«‹æ±‚ç‰©ä»¶ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦çš„æ¬„ä½
        request = model_service_pb2.TranslateRequest(
            text_to_translate=text,
            source_language=src_lang,
            target_language=tgt_lang
        )
        
        # å‘¼å«é ç«¯çš„ Translate æœå‹™
        response = stub.Translate(request)
        
        print(f"âœ… [å®¢æˆ¶ç«¯] æ”¶åˆ°ç¿»è­¯çµæœ: '{response.translated_text}'")
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] ç¿»è­¯è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")

def run_speaker_identification_test(stub, audio_file_path):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨ä¾†åŸ·è¡Œè¬›è€…åˆ†è¾¨ä¸¦å°å‡ºçµæœ"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€è¬›è€…åˆ†è¾¨è«‹æ±‚: '{audio_file_path}'")
    
    try:
        # è®€å–éŸ³è¨Šæª”æ¡ˆ
        with open(audio_file_path, "rb") as f:
            audio_data = f.read()
        
        print(f"ğŸ“ éŸ³è¨Šæª”æ¡ˆå¤§å°: {len(audio_data)} bytes")
        
        # æº–å‚™è«‹æ±‚ç‰©ä»¶ - æ ¹æ“šå¯¦éš› proto å®šç¾©
        request = model_service_pb2.SpeakerAnnoteRequest(
            audio_data=audio_data
        )
        
        # å‘¼å«é ç«¯çš„ SpeakerAnnote æœå‹™
        response = stub.SpeakerAnnote(request)
        
        # æ ¹æ“šå¯¦éš›çš„ proto å®šç¾©è™•ç†å›æ‡‰
        print("âœ… [å®¢æˆ¶ç«¯] è¬›è€…åˆ†è¾¨çµæœ:")
        
        # è™•ç† all_segments (æ‰€æœ‰åˆ†å‰²ç‰‡æ®µ)
        if response.all_segments:
            print(f"ğŸ“Š ç¸½å…±æ‰¾åˆ° {len(response.all_segments)} å€‹èªéŸ³ç‰‡æ®µ:")
            for i, segment in enumerate(response.all_segments):
                print(f"  ğŸ¤ ç‰‡æ®µ {i+1}: {segment.speaker} ({segment.start_time:.2f}s - {segment.end_time:.2f}s)")
        
        # è™•ç† speaker_timelines (æŒ‰è¬›è€…åˆ†çµ„çš„æ™‚é–“è»¸)
        if response.speaker_timelines:
            print(f"\nğŸ‘¥ ç™¼ç¾ {len(response.speaker_timelines)} ä½è¬›è€…:")
            for timeline in response.speaker_timelines:
                speaker_name = timeline.speaker
                segment_count = len(timeline.segments)
                total_duration = sum(seg.end_time - seg.start_time for seg in timeline.segments)
                
                print(f"  ğŸ—£ï¸  {speaker_name}:")
                print(f"      ğŸ“ˆ èªªè©±ç‰‡æ®µæ•¸: {segment_count}")
                print(f"      â±ï¸  ç¸½èªªè©±æ™‚é–“: {total_duration:.2f} ç§’")
                print(f"      ğŸ“‹ è©³ç´°ç‰‡æ®µ:")
                
                for j, segment in enumerate(timeline.segments):
                    duration = segment.end_time - segment.start_time
                    print(f"          {j+1}. {segment.start_time:.2f}s - {segment.end_time:.2f}s ({duration:.2f}s)")
        
        # å¦‚æœæ²’æœ‰ä»»ä½•çµæœ
        if not response.all_segments and not response.speaker_timelines:
            print("âš ï¸ æ²’æœ‰æª¢æ¸¬åˆ°ä»»ä½•è¬›è€…æˆ–èªéŸ³ç‰‡æ®µ")
            print("   é€™å¯èƒ½æ˜¯å› ç‚º:")
            print("   - éŸ³è¨Šæª”æ¡ˆå¤ªçŸ­")
            print("   - éŸ³è¨Šå“è³ªä¸ä½³")
            print("   - æ²’æœ‰åŒ…å«èªéŸ³å…§å®¹")
            print("   - ä¼ºæœå™¨ç«¯æ¨¡å‹å°šæœªå®Œå…¨å¯¦ç¾")
            
    except FileNotFoundError:
        print(f"âŒ [å®¢æˆ¶ç«¯] æ‰¾ä¸åˆ°éŸ³è¨Šæª”æ¡ˆ: {audio_file_path}")
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è¬›è€…åˆ†è¾¨è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")
    except Exception as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è™•ç†è¬›è€…åˆ†è¾¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


def run_wav2lip_test(stub, audio_file_path, image_file_path, output_filename="output_wav2lip.mp4"):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨ä¾†åŸ·è¡Œ Wav2Lip å°å˜´å½±ç‰‡ç”Ÿæˆ"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ Wav2Lip è«‹æ±‚: éŸ³è¨Š='{audio_file_path}', åœ–ç‰‡='{image_file_path}'")
    
    try:
        # è®€å–éŸ³è¨Šå’Œåœ–ç‰‡æª”æ¡ˆ
        with open(audio_file_path, "rb") as f:
            audio_data = f.read()
        
        with open(image_file_path, "rb") as f:
            image_data = f.read()
        
        # æº–å‚™è«‹æ±‚ç‰©ä»¶
        request = model_service_pb2.Wav2LipRequest(
            audio_data=audio_data,
            image_data=image_data
        )
        
        # å‘¼å«é ç«¯çš„ Wav2Lip æœå‹™
        response = stub.Wav2Lip(request)
        
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦æœ‰å½±ç‰‡è³‡æ–™
        if response.video_data:
            with open(output_filename, "wb") as f:
                f.write(response.video_data)
            print(f"âœ… [å®¢æˆ¶ç«¯] æ”¶åˆ° Wav2Lip å½±ç‰‡ï¼Œå·²ä¿å­˜è‡³ {output_filename}")
        else:
            print("âŒ [å®¢æˆ¶ç«¯] ä¼ºæœå™¨å›å‚³äº†ç©ºçš„å½±ç‰‡è³‡æ–™ã€‚")
            
    except FileNotFoundError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] æ‰¾ä¸åˆ°æª”æ¡ˆ: {e}")
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] Wav2Lip è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")
    except Exception as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è™•ç† Wav2Lip æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def run_llm_text_generation_test(stub, prompt, max_tokens=100, temperature=0.7):
    """æ¸¬è©¦ LLM æ–‡æœ¬ç”ŸæˆåŠŸèƒ½"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ LLM æ–‡æœ¬ç”Ÿæˆè«‹æ±‚: '{prompt}'")
    
    try:
        # æº–å‚™è«‹æ±‚ç‰©ä»¶
        request = model_service_pb2.TextGenerationRequest(
            prompt=prompt,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=0.9
        )
        
        # å‘¼å«é ç«¯çš„ GenerateText æœå‹™
        response = stub.GenerateText(request)
        
        # æª¢æŸ¥å›æ‡‰
        if response.success:
            print(f"âœ… [å®¢æˆ¶ç«¯] LLM æ–‡æœ¬ç”ŸæˆæˆåŠŸ:")
            print(f"ğŸ“„ çµæœ: {response.generated_text}")
        else:
            print("âŒ [å®¢æˆ¶ç«¯] LLM æ–‡æœ¬ç”Ÿæˆå¤±æ•—")
            
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] LLM æ–‡æœ¬ç”Ÿæˆè«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")
    except Exception as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è™•ç† LLM æ–‡æœ¬ç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def run_llm_chat_test(stub, messages, max_tokens=120, temperature=0.7):
    """æ¸¬è©¦ LLM å°è©±åŠŸèƒ½"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ LLM å°è©±è«‹æ±‚:")
    
    # é¡¯ç¤ºå°è©±å…§å®¹
    for msg in messages:
        role_icon = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–" if msg["role"] == "assistant" else "âš™ï¸"
        print(f"  {role_icon} {msg['role']}: {msg['content']}")
    
    try:
        # æ§‹å»º gRPC æ¶ˆæ¯
        grpc_messages = []
        for msg in messages:
            grpc_messages.append(
                model_service_pb2.ChatMessage(
                    role=msg["role"],
                    content=msg["content"]
                )
            )
        
        # æº–å‚™è«‹æ±‚ç‰©ä»¶
        request = model_service_pb2.ChatCompletionRequest(
            messages=grpc_messages,
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        # å‘¼å«é ç«¯çš„ ChatCompletion æœå‹™
        response = stub.ChatCompletion(request)
        
        # æª¢æŸ¥å›æ‡‰
        if response.success:
            print(f"âœ… [å®¢æˆ¶ç«¯] LLM å°è©±æˆåŠŸ:")
            print(f"ğŸ¤– åŠ©æ‰‹å›æ‡‰: {response.response}")
        else:
            print("âŒ [å®¢æˆ¶ç«¯] LLM å°è©±å¤±æ•—")
            
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] LLM å°è©±è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")
    except Exception as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è™•ç† LLM å°è©±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def run_llm_comprehensive_test(stub):
    """åŸ·è¡Œ LLM çš„å®Œæ•´æ¸¬è©¦å¥—ä»¶"""
    print("\nğŸ¤– æ¸¬è©¦ LLM æœå‹™:")
    print("-" * 30)
    
    # æ¸¬è©¦ 1: åŸºæœ¬æ–‡æœ¬ç”Ÿæˆ
    print("\nğŸ“ æ¸¬è©¦ 1: åŸºæœ¬æ–‡æœ¬ç”Ÿæˆ")
    text_prompts = [
        "The future of artificial intelligence is",
        "äººå·¥æ™ºæ…§çš„æ‡‰ç”¨åŒ…æ‹¬",
        "Technology has changed our lives by",
        "åœ¨æœªä¾†åå¹´ï¼Œç§‘æŠ€ç™¼å±•å°‡æœƒ"
    ]
    
    for prompt in text_prompts:
        run_llm_text_generation_test(stub, prompt, max_tokens=80, temperature=0.7)
    
    # æ¸¬è©¦ 2: ä¸åŒæº«åº¦åƒæ•¸
    print("\nğŸŒ¡ï¸ æ¸¬è©¦ 2: ä¸åŒæº«åº¦åƒæ•¸å°æ¯”")
    base_prompt = "The benefits of machine learning include"
    temperatures = [0.3, 0.7, 1.0]
    
    for temp in temperatures:
        print(f"\nğŸ”¥ æº«åº¦ {temp}:")
        run_llm_text_generation_test(stub, base_prompt, max_tokens=60, temperature=temp)
    
    # æ¸¬è©¦ 3: åŸºæœ¬å°è©±
    print("\nğŸ’¬ æ¸¬è©¦ 3: åŸºæœ¬å°è©±")
    
    basic_conversations = [
        [{"role": "user", "content": "Hello! How are you?"}],
        [{"role": "user", "content": "ä½ å¥½ï¼è«‹ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}],
        [{"role": "user", "content": "What can you help me with?"}],
        [{"role": "user", "content": "Tell me about artificial intelligence."}]
    ]
    
    for i, conversation in enumerate(basic_conversations, 1):
        print(f"\nğŸ’­ å°è©± {i}:")
        run_llm_chat_test(stub, conversation, max_tokens=100, temperature=0.7)
    
    # æ¸¬è©¦ 4: ç³»çµ±æç¤ºå°è©±
    print("\nğŸ­ æ¸¬è©¦ 4: è§’è‰²æ‰®æ¼”å°è©±ï¼ˆç³»çµ±æç¤ºï¼‰")
    
    role_conversations = [
        [
            {"role": "system", "content": "You are a helpful programming assistant."}, 
            {"role": "user", "content": "Explain what is Python programming language."}
        ],
        [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å‹å–„çš„ä¸­æ–‡åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "è«‹è§£é‡‹ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ã€‚"},
        ],
        [
            {"role": "system", "content": "You are a creative writer who loves storytelling."}, 
            {"role": "user", "content": "Write the beginning of a short story about robots."}
        ]
    ]
    
    for i, conversation in enumerate(role_conversations, 1):
        print(f"\nğŸª è§’è‰²å°è©± {i}:")
        run_llm_chat_test(stub, conversation, max_tokens=120, temperature=0.8)
    
    # æ¸¬è©¦ 5: å¤šè¼ªå°è©±
    print("\nğŸ”„ æ¸¬è©¦ 5: å¤šè¼ªå°è©±")
    
    # æ¨¡æ“¬ä¸€å€‹é€£çºŒçš„å°è©±
    conversation_history = []
    user_inputs = [
        "Hi, I want to learn about machine learning.",
        "What are the main types of machine learning?",
        "Can you give me an example of supervised learning?",
        "Thank you for the explanation!"
    ]
    
    for turn, user_input in enumerate(user_inputs, 1):
        print(f"\nğŸ”„ å°è©±å›åˆ {turn}:")
        
        # æ·»åŠ ç”¨æˆ¶è¼¸å…¥åˆ°æ­·å²
        conversation_history.append({"role": "user", "content": user_input})
        
        # åŸ·è¡Œå°è©±
        run_llm_chat_test(stub, conversation_history, max_tokens=100, temperature=0.6)
        
        # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘æ²’æœ‰çœŸçš„æŠŠåŠ©æ‰‹å›æ‡‰åŠ åˆ°æ­·å²ä¸­
        # å› ç‚ºæˆ‘å€‘ç„¡æ³•å¾ run_llm_chat_test å–å¾—å›æ‡‰
        # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œæ‚¨æœƒæƒ³è¦ä¿å­˜å›æ‡‰ä¸¦åŠ åˆ°æ­·å²ä¸­

def main():
    # é€£æ¥åˆ° gRPC ä¼ºæœå™¨
    print("ğŸ”— æ­£åœ¨é€£æ¥åˆ° gRPC ä¼ºæœå™¨...")
    
    # --- ä¿®æ”¹è™•ï¼šåœ¨é€™è£¡åŠ å…¥ options ---
    channel_options = [
        ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),
        ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),
        ('grpc.max_receive_metadata_size', MAX_METADATA_SIZE),
        ('grpc.max_send_metadata_size', MAX_METADATA_SIZE),
    ]
    
    with grpc.insecure_channel('localhost:50051', options=channel_options) as channel:
        # å»ºç«‹å®¢æˆ¶ç«¯ Stub
        translator_stub = model_service_pb2_grpc.TranslatorServiceStub(channel)
        media_stub = model_service_pb2_grpc.MediaServiceStub(channel)

        print("\n" + "="*60)
        print("ğŸš€ é–‹å§‹æ¸¬è©¦æ‰€æœ‰æœå‹™åŠŸèƒ½")
        print("="*60)

        # --- åŸ·è¡Œ RAG å•ç­”æ¸¬è©¦ ---
        print("\nğŸ“š æ¸¬è©¦ RAG å•ç­”æœå‹™:")
        print("-" * 30)
        run_rag_qa_test(media_stub, "é ç®—è¶…æ”¯å¤šå°‘ï¼Ÿ")
        run_rag_qa_test(media_stub, "What is the core function of the immersive assistant?")

        # --- åŸ·è¡Œ LLM æ¸¬è©¦ ---
        run_llm_comprehensive_test(media_stub)

        # --- åŸ·è¡Œç¿»è­¯æ¸¬è©¦ ---
        print("\nğŸ“ æ¸¬è©¦ç¿»è­¯æœå‹™:")
        print("-" * 30)
        run_translation_test(translator_stub, "Hello world", "è‹±æ–‡", "ä¸­æ–‡")
        run_translation_test(translator_stub, "é€™æ˜¯å€‹å¾ˆæ£’çš„ç³»çµ±", "ä¸­æ–‡", "æ—¥æ–‡")
        run_translation_test(translator_stub, "Wie geht es Ihnen?", "å¾·æ–‡", "è‹±æ–‡")
        run_translation_test(translator_stub, "Ceci est un test.", "æ³•æ–‡", "è¥¿ç­ç‰™æ–‡")
        # æ¸¬è©¦ä¸€å€‹ä¸æ”¯æ´çš„èªè¨€
        run_translation_test(translator_stub, "Test", "è‹±æ–‡", "ç«æ˜Ÿæ–‡")

        # --- åŸ·è¡Œ TTS æ¸¬è©¦ ---
        print("\nğŸ¤ æ¸¬è©¦ TTS æœå‹™:")
        print("-" * 30)
        run_tts_test(media_stub, "This is a test of the text to speech API.", "en", "output_en.wav")
        run_tts_test(media_stub, "ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹èªéŸ³åˆæˆçš„æ¸¬è©¦ã€‚", "zh-cn", "output_zh-cn.wav")

        # --- åŸ·è¡Œè¬›è€…åˆ†è¾¨æ¸¬è©¦ ---
        print("\nğŸ‘¥ æ¸¬è©¦è¬›è€…åˆ†è¾¨æœå‹™:")
        print("-" * 30)
        
        # æ–¹æ³• 1: ä½¿ç”¨ç¾æœ‰çš„éŸ³è¨Šæª”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        existing_audio_files = [
            "./identify_sample/ta.wav",
        ]
        
        test_file_found = False
        for audio_file in existing_audio_files:
            try:
                with open(audio_file, 'rb'):
                    print(f"ğŸ“ ä½¿ç”¨ç¾æœ‰éŸ³è¨Šæª”æ¡ˆé€²è¡Œæ¸¬è©¦: {audio_file}")
                    run_speaker_identification_test(media_stub, audio_file)
                    test_file_found = True
                    break
            except FileNotFoundError:
                continue

        # --- åŸ·è¡Œ Wav2Lip æ¸¬è©¦ ---
        print("\nğŸ¬ æ¸¬è©¦ Wav2Lip æœå‹™:")
        print("-" * 30)
        
        audio_file_path = "wav2lip_sample/chinese_news.wav"
        image_file_path = "wav2lip_sample/tom.jpg"

        try:
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
            with open(audio_file_path, 'rb'):
                pass
            with open(image_file_path, 'rb'):
                pass
            
            print(f"ğŸ“ ä½¿ç”¨éŸ³è¨Šæª”æ¡ˆ: {audio_file_path}, åœ–ç‰‡æª”æ¡ˆ: {image_file_path}")
            run_wav2lip_test(media_stub, audio_file_path, image_file_path)

        except FileNotFoundError:
            print(f"âš ï¸ æ‰¾ä¸åˆ°æ¸¬è©¦æª”æ¡ˆï¼Œè·³é Wav2Lip æ¸¬è©¦ã€‚")
            print(f"   è«‹ç¢ºèª '{audio_file_path}' å’Œ '{image_file_path}' æ˜¯å¦å­˜åœ¨ã€‚")

        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print("="*60)

if __name__ == '__main__':
    main()
