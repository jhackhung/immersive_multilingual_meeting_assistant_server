# æª”æ¡ˆ: client.py

import grpc
import numpy as np
import wave
from proto import model_service_pb2
from proto import model_service_pb2_grpc

# --- æ–°å¢ï¼šå®šç¾©èˆ‡ä¼ºæœå™¨ç«¯åŒ¹é…çš„è¨Šæ¯é•·åº¦é™åˆ¶ ---
MAX_MESSAGE_LENGTH = 100 * 1024 * 1024

def run_tts_test(stub, text, language, output_filename):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨ä¾†åŸ·è¡Œå–®æ¬¡ TTS ä¸¦å„²å­˜çµæœ"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ TTS è«‹æ±‚: '{text}' (èªè¨€: {language})")
    try:
        # æº–å‚™è«‹æ±‚ç‰©ä»¶ï¼ŒåŒ…å«æ–‡å­—å’Œèªè¨€
        reference_audio_file_path = "./tts_sample/en_sample.wav"
        with open(reference_audio_file_path, "rb") as f:
            reference_audio = f.read()
        # æº–å‚™è«‹æ±‚ç‰©ä»¶ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦çš„æ¬„ä½
        
        request = model_service_pb2.TtsRequest(
            text_to_speak=text,
            language=language,
            reference_audio=reference_audio
        )
        
        # å‘¼å«é ç«¯çš„ Tts æœå‹™
        response = stub.Tts(request)
        
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦æœ‰éŸ³è¨Šè³‡æ–™
        if response.generated_audio:
            with open(output_filename, "wb") as f:
                f.write(response.generated_audio)
            print(f"âœ… [å®¢æˆ¶ç«¯] æ”¶åˆ°éŸ³è¨Šå›æ‡‰ï¼Œå·²ä¿å­˜è‡³ {output_filename}")
        else:
            print("âŒ [å®¢æˆ¶ç«¯] ä¼ºæœå™¨å›å‚³äº†ç©ºçš„éŸ³è¨Šã€‚")
            
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] TTS è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")

def run_translation_test(stub, text, src_lang, tgt_lang):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨ä¾†åŸ·è¡Œå–®æ¬¡ç¿»è­¯ä¸¦å°å‡ºçµæœ"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ç¿»è­¯è«‹æ±‚: '{text}' ({src_lang} -> {tgt_lang})")
    
    try:
        # æº–å‚™è«‹æ±‚ç‰©ä»¶ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦çš„æ¬„ä½
        request = model_service_pb2.TranslateRequest(
            text_to_translate=text,
            source_language=src_lang,
            target_language=tgt_lang
        )
        
        # å‘¼å«é ç«¯çš„ Translate æœå‹™
        response = stub.Translate(request)
        
        print(f"âœ… [å®¢æˆ¶ç«¯] æ”¶åˆ°ç¿»è­¯çµæœ: '{response.translated_text}'")
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] ç¿»è­¯è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")

def run_speaker_identification_test(stub, audio_file_path):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨ä¾†åŸ·è¡Œè¬›è€…åˆ†è¾¨ä¸¦å°å‡ºçµæœ"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€è¬›è€…åˆ†è¾¨è«‹æ±‚: '{audio_file_path}'")
    
    try:
        # è®€å–éŸ³è¨Šæª”æ¡ˆ
        with open(audio_file_path, "rb") as f:
            audio_data = f.read()
        
        print(f"ğŸ“ éŸ³è¨Šæª”æ¡ˆå¤§å°: {len(audio_data)} bytes")
        
        # æº–å‚™è«‹æ±‚ç‰©ä»¶ - æ ¹æ“šå¯¦éš› proto å®šç¾©
        request = model_service_pb2.SpeakerAnnoteRequest(
            audio_data=audio_data
        )
        
        # å‘¼å«é ç«¯çš„ SpeakerAnnote æœå‹™
        response = stub.SpeakerAnnote(request)
        
        # æ ¹æ“šå¯¦éš›çš„ proto å®šç¾©è™•ç†å›æ‡‰
        print("âœ… [å®¢æˆ¶ç«¯] è¬›è€…åˆ†è¾¨çµæœ:")
        
        # è™•ç† all_segments (æ‰€æœ‰åˆ†å‰²ç‰‡æ®µ)
        if response.all_segments:
            print(f"ğŸ“Š ç¸½å…±æ‰¾åˆ° {len(response.all_segments)} å€‹èªéŸ³ç‰‡æ®µ:")
            for i, segment in enumerate(response.all_segments):
                print(f"  ğŸ¤ ç‰‡æ®µ {i+1}: {segment.speaker} ({segment.start_time:.2f}s - {segment.end_time:.2f}s)")
        
        # è™•ç† speaker_timelines (æŒ‰è¬›è€…åˆ†çµ„çš„æ™‚é–“è»¸)
        if response.speaker_timelines:
            print(f"\nğŸ‘¥ ç™¼ç¾ {len(response.speaker_timelines)} ä½è¬›è€…:")
            for timeline in response.speaker_timelines:
                speaker_name = timeline.speaker
                segment_count = len(timeline.segments)
                total_duration = sum(seg.end_time - seg.start_time for seg in timeline.segments)
                
                print(f"  ğŸ—£ï¸  {speaker_name}:")
                print(f"      ğŸ“ˆ èªªè©±ç‰‡æ®µæ•¸: {segment_count}")
                print(f"      â±ï¸  ç¸½èªªè©±æ™‚é–“: {total_duration:.2f} ç§’")
                print(f"      ğŸ“‹ è©³ç´°ç‰‡æ®µ:")
                
                for j, segment in enumerate(timeline.segments):
                    duration = segment.end_time - segment.start_time
                    print(f"          {j+1}. {segment.start_time:.2f}s - {segment.end_time:.2f}s ({duration:.2f}s)")
        
        # å¦‚æœæ²’æœ‰ä»»ä½•çµæœ
        if not response.all_segments and not response.speaker_timelines:
            print("âš ï¸ æ²’æœ‰æª¢æ¸¬åˆ°ä»»ä½•è¬›è€…æˆ–èªéŸ³ç‰‡æ®µ")
            print("   é€™å¯èƒ½æ˜¯å› ç‚º:")
            print("   - éŸ³è¨Šæª”æ¡ˆå¤ªçŸ­")
            print("   - éŸ³è¨Šå“è³ªä¸ä½³")
            print("   - æ²’æœ‰åŒ…å«èªéŸ³å…§å®¹")
            print("   - ä¼ºæœå™¨ç«¯æ¨¡å‹å°šæœªå®Œå…¨å¯¦ç¾")
            
    except FileNotFoundError:
        print(f"âŒ [å®¢æˆ¶ç«¯] æ‰¾ä¸åˆ°éŸ³è¨Šæª”æ¡ˆ: {audio_file_path}")
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è¬›è€…åˆ†è¾¨è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")
    except Exception as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è™•ç†è¬›è€…åˆ†è¾¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


def run_wav2lip_test(stub, audio_file_path, image_file_path, output_filename="output_wav2lip.mp4"):
    """ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨ä¾†åŸ·è¡Œ Wav2Lip å°å˜´å½±ç‰‡ç”Ÿæˆ"""
    print(f"\n[å®¢æˆ¶ç«¯] ç™¼é€ Wav2Lip è«‹æ±‚: éŸ³è¨Š='{audio_file_path}', åœ–ç‰‡='{image_file_path}'")
    
    try:
        # è®€å–éŸ³è¨Šå’Œåœ–ç‰‡æª”æ¡ˆ
        with open(audio_file_path, "rb") as f:
            audio_data = f.read()
        
        with open(image_file_path, "rb") as f:
            image_data = f.read()
        
        # æº–å‚™è«‹æ±‚ç‰©ä»¶
        request = model_service_pb2.Wav2LipRequest(
            audio_data=audio_data,
            image_data=image_data
        )
        
        # å‘¼å«é ç«¯çš„ Wav2Lip æœå‹™
        response = stub.Wav2Lip(request)
        
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦æœ‰å½±ç‰‡è³‡æ–™
        if response.video_data:
            with open(output_filename, "wb") as f:
                f.write(response.video_data)
            print(f"âœ… [å®¢æˆ¶ç«¯] æ”¶åˆ° Wav2Lip å½±ç‰‡ï¼Œå·²ä¿å­˜è‡³ {output_filename}")
        else:
            print("âŒ [å®¢æˆ¶ç«¯] ä¼ºæœå™¨å›å‚³äº†ç©ºçš„å½±ç‰‡è³‡æ–™ã€‚")
            
    except FileNotFoundError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] æ‰¾ä¸åˆ°æª”æ¡ˆ: {e}")
    except grpc.RpcError as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] Wav2Lip è«‹æ±‚å¤±æ•—: {e.code()} - {e.details()}")
    except Exception as e:
        print(f"âŒ [å®¢æˆ¶ç«¯] è™•ç† Wav2Lip æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def main():
    # é€£æ¥åˆ° gRPC ä¼ºæœå™¨
    print("ğŸ”— æ­£åœ¨é€£æ¥åˆ° gRPC ä¼ºæœå™¨...")
    
    # --- ä¿®æ”¹è™•ï¼šåœ¨é€™è£¡åŠ å…¥ options ---
    channel_options = [
        ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),
        ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),
    ]
    
    with grpc.insecure_channel('localhost:50051', options=channel_options) as channel:
        # å»ºç«‹å®¢æˆ¶ç«¯ Stub
        translator_stub = model_service_pb2_grpc.TranslatorServiceStub(channel)
        media_stub = model_service_pb2_grpc.MediaServiceStub(channel)

        print("\n" + "="*60)
        print("ğŸš€ é–‹å§‹æ¸¬è©¦æ‰€æœ‰æœå‹™åŠŸèƒ½")
        print("="*60)

        # --- åŸ·è¡Œç¿»è­¯æ¸¬è©¦ ---
        print("\nğŸ“ æ¸¬è©¦ç¿»è­¯æœå‹™:")
        print("-" * 30)
        run_translation_test(translator_stub, "Hello world", "è‹±æ–‡", "ä¸­æ–‡")
        run_translation_test(translator_stub, "é€™æ˜¯å€‹å¾ˆæ£’çš„ç³»çµ±", "ä¸­æ–‡", "æ—¥æ–‡")
        run_translation_test(translator_stub, "Wie geht es Ihnen?", "å¾·æ–‡", "è‹±æ–‡")
        run_translation_test(translator_stub, "Ceci est un test.", "æ³•æ–‡", "è¥¿ç­ç‰™æ–‡")
        # æ¸¬è©¦ä¸€å€‹ä¸æ”¯æ´çš„èªè¨€
        run_translation_test(translator_stub, "Test", "è‹±æ–‡", "ç«æ˜Ÿæ–‡")

        # --- åŸ·è¡Œ TTS æ¸¬è©¦ ---
        print("\nğŸ¤ æ¸¬è©¦ TTS æœå‹™:")
        print("-" * 30)
        run_tts_test(media_stub, "This is a test of the text to speech API.", "en", "output_en.wav")
        run_tts_test(media_stub, "ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹èªéŸ³åˆæˆçš„æ¸¬è©¦ã€‚", "zh-cn", "output_zh-cn.wav")

        # --- åŸ·è¡Œè¬›è€…åˆ†è¾¨æ¸¬è©¦ ---
        print("\nğŸ‘¥ æ¸¬è©¦è¬›è€…åˆ†è¾¨æœå‹™:")
        print("-" * 30)
        
        # æ–¹æ³• 1: ä½¿ç”¨ç¾æœ‰çš„éŸ³è¨Šæª”æ¡ˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        existing_audio_files = [
            "./identify_sample/ta.wav",
        ]
        
        test_file_found = False
        for audio_file in existing_audio_files:
            try:
                with open(audio_file, 'rb'):
                    print(f"ğŸ“ ä½¿ç”¨ç¾æœ‰éŸ³è¨Šæª”æ¡ˆé€²è¡Œæ¸¬è©¦: {audio_file}")
                    run_speaker_identification_test(media_stub, audio_file)
                    test_file_found = True
                    break
            except FileNotFoundError:
                continue

        # --- åŸ·è¡Œ Wav2Lip æ¸¬è©¦ï¼ˆå¯é¸ï¼Œéœ€è¦åœ–ç‰‡æª”æ¡ˆï¼‰ ---
        print("\nğŸ¬ æ¸¬è©¦ Wav2Lip æœå‹™:")
        print("-" * 30)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ¸¬è©¦ç”¨çš„åœ–ç‰‡æª”æ¡ˆ
        test_image_files = ["test_face.jpg", "test_face.png", "sample_face.jpg"]
        image_file_found = False
        
        for image_file in test_image_files:
            try:
                with open(image_file, 'rb'):
                    audio_file = "output_en.wav"  # ä½¿ç”¨ä¹‹å‰ç”Ÿæˆçš„éŸ³è¨Š
                    try:
                        with open(audio_file, 'rb'):
                            print(f"ğŸ“ ä½¿ç”¨éŸ³è¨Šæª”æ¡ˆ: {audio_file}, åœ–ç‰‡æª”æ¡ˆ: {image_file}")
                            run_wav2lip_test(media_stub, audio_file, image_file)
                            image_file_found = True
                            break
                    except FileNotFoundError:
                        print(f"âš ï¸ æ‰¾ä¸åˆ°éŸ³è¨Šæª”æ¡ˆ {audio_file}ï¼Œè·³é Wav2Lip æ¸¬è©¦")
                        break
            except FileNotFoundError:
                continue
        
        if not image_file_found:
            print("âš ï¸ æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦ç”¨çš„åœ–ç‰‡æª”æ¡ˆï¼Œè·³é Wav2Lip æ¸¬è©¦")
            print("   å¦‚éœ€æ¸¬è©¦ Wav2Lipï¼Œè«‹æº–å‚™ test_face.jpg æˆ– test_face.png")

        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print("="*60)

if __name__ == '__main__':
    main()